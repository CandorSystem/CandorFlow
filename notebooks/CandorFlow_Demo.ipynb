{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŒŠ CandorFlow Interactive Demo\n",
        "\n",
        "## Early Warning System for Training Instabilities\n",
        "\n",
        "---\n",
        "\n",
        "### âš ï¸ **Important Notice**\n",
        "\n",
        "**This notebook contains a SIMPLIFIED, EDUCATIONAL demonstration of CandorFlow concepts.**\n",
        "\n",
        "This is **NOT the full proprietary system**. Many advanced algorithms and features are intentionally excluded, including:\n",
        "- Universal scaling laws\n",
        "- Reflexive ridge computations\n",
        "- Cross-domain invariants\n",
        "- Advanced control algorithms\n",
        "- Production optimizations\n",
        "\n",
        "For information about the complete system, please contact the authors.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“– What You'll Learn\n",
        "\n",
        "In this notebook, you will:\n",
        "\n",
        "1. âœ… Understand the **Î»(t) stability metric** (simplified version)\n",
        "2. âœ… See how to **monitor training instabilities** in real-time\n",
        "3. âœ… Learn about **automatic intervention** (rollback + LR reduction)\n",
        "4. âœ… Visualize **stability patterns** during training\n",
        "5. âœ… Run a **complete training demo** with intentional instability\n",
        "\n",
        "Let's get started! ðŸš€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (uncomment if needed)\n",
        "# !pip install torch transformers numpy matplotlib\n",
        "\n",
        "# Imports\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "# Import CandorFlow\n",
        "from candorflow import compute_lambda, StabilityController\n",
        "from candorflow.utils import set_seed, get_logger\n",
        "from candorflow.lambda_metric import compute_lambda_metric_simple\n",
        "\n",
        "print(\"âœ“ All imports successful!\")\n",
        "print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
        "print(f\"âœ“ Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Understanding Î»(t)\n",
        "\n",
        "The **lambda metric Î»(t)** is a stability indicator that tracks training health over time.\n",
        "\n",
        "### Simplified Version (This Demo)\n",
        "\n",
        "In this demo, Î»(t) is computed as:\n",
        "\n",
        "```\n",
        "Î»(t) = Var(âˆ‡) / Mean(âˆ‡)Â²\n",
        "```\n",
        "\n",
        "Where `âˆ‡` represents recent gradient norms.\n",
        "\n",
        "**Interpretation:**\n",
        "- **Low Î»(t)**: Gradients are stable and consistent â†’ Training is healthy\n",
        "- **High Î»(t)**: Gradients are erratic and varying wildly â†’ Instability approaching\n",
        "\n",
        "### What's Missing (Proprietary)\n",
        "\n",
        "The full CandorFlow Î»(t) includes:\n",
        "- Jacobian spectral analysis\n",
        "- Universal scaling laws\n",
        "- Reflexive ridge computations\n",
        "- Multi-signal fusion\n",
        "- Cross-domain invariants\n",
        "\n",
        "Let's see the simplified metric in action!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple toy model\n",
        "class TinyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(10, 20)\n",
        "        self.fc2 = nn.Linear(20, 20)\n",
        "        self.fc3 = nn.Linear(20, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Initialize\n",
        "set_seed(42)\n",
        "model = TinyModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"âœ“ Created tiny model with 3 layers\")\n",
        "print(f\"âœ“ Total parameters: {sum(p.numel() for p in model.parameters())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate Î»(t) computation on stable vs unstable gradients\n",
        "\n",
        "gradient_history_stable = []\n",
        "gradient_history_unstable = []\n",
        "\n",
        "# Simulate stable training\n",
        "print(\"Simulating STABLE gradients:\")\n",
        "for i in range(10):\n",
        "    # Stable: gradients around 1.0 with small noise\n",
        "    grad_norm = 1.0 + np.random.normal(0, 0.1)\n",
        "    gradient_history_stable.append(grad_norm)\n",
        "    print(f\"  Step {i}: grad_norm = {grad_norm:.4f}\")\n",
        "\n",
        "lambda_stable = compute_lambda_metric_simple(gradient_history_stable)\n",
        "print(f\"\\nâœ“ Stable Î»(t) = {lambda_stable:.4f}\\n\")\n",
        "\n",
        "# Simulate unstable training\n",
        "print(\"Simulating UNSTABLE gradients:\")\n",
        "for i in range(10):\n",
        "    # Unstable: wild gradient swings\n",
        "    grad_norm = 1.0 + np.random.normal(0, 2.0)  # Much larger variance\n",
        "    gradient_history_unstable.append(grad_norm)\n",
        "    print(f\"  Step {i}: grad_norm = {grad_norm:.4f}\")\n",
        "\n",
        "lambda_unstable = compute_lambda_metric_simple(gradient_history_unstable)\n",
        "print(f\"\\nâœ“ Unstable Î»(t) = {lambda_unstable:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Comparison: Unstable Î»(t) is {lambda_unstable/lambda_stable:.1f}x higher!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Training with Stability Monitoring\n",
        "\n",
        "Now let's train a model with CandorFlow monitoring:\n",
        "\n",
        "1. **Normal training** â†’ Î»(t) stays low, no intervention\n",
        "2. **Inject instability** â†’ Î»(t) spikes\n",
        "3. **Automatic rollback** â†’ Controller restores stability\n",
        "\n",
        "This demonstrates the basic autopilot functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup training\n",
        "set_seed(42)\n",
        "model = TinyModel()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Create stability controller\n",
        "controller = StabilityController(\n",
        "    threshold=1.5,  # Intervene when Î»(t) > 1.5\n",
        "    checkpoint_dir=\"../checkpoints_demo\",\n",
        "    lr_reduction_factor=0.5\n",
        ")\n",
        "\n",
        "# Training loop\n",
        "num_steps = 40\n",
        "gradient_history = []\n",
        "lambda_values = []\n",
        "losses = []\n",
        "actions_taken = []\n",
        "\n",
        "print(\"ðŸš€ Starting training with stability monitoring...\\n\")\n",
        "\n",
        "for step in range(num_steps):\n",
        "    # Generate dummy batch\n",
        "    X = torch.randn(16, 10)\n",
        "    y = torch.randint(0, 2, (16,))\n",
        "    \n",
        "    # Forward pass\n",
        "    model.train()\n",
        "    outputs = model(X)\n",
        "    loss = criterion(outputs, y)\n",
        "    losses.append(loss.item())\n",
        "    \n",
        "    # Compute Î»(t)\n",
        "    lambda_value = compute_lambda(\n",
        "        model=model,\n",
        "        loss=loss,\n",
        "        history_window=10,\n",
        "        gradient_history=gradient_history\n",
        "    )\n",
        "    lambda_values.append(lambda_value)\n",
        "    \n",
        "    # Update controller\n",
        "    action = controller.update(\n",
        "        lambda_value=lambda_value,\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        step=step\n",
        "    )\n",
        "    actions_taken.append(action)\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    \n",
        "    # INJECT INSTABILITY after step 25\n",
        "    if step >= 25:\n",
        "        # Add large noise to gradients\n",
        "        for param in model.parameters():\n",
        "            if param.grad is not None:\n",
        "                noise = torch.randn_like(param.grad) * 3.0 * (step - 24)\n",
        "                param.grad.data += noise\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    # Logging\n",
        "    if step % 5 == 0 or action[\"action\"] != \"none\":\n",
        "        status = \"ðŸŸ¢\" if lambda_value < 1.0 else \"ðŸŸ¡\" if lambda_value < 1.5 else \"ðŸ”´\"\n",
        "        print(f\"{status} Step {step:2d} | Loss: {loss.item():.4f} | Î»(t): {lambda_value:.4f} | {action['action']}\")\n",
        "\n",
        "print(\"\\nâœ“ Training complete!\")\n",
        "\n",
        "# Summary\n",
        "summary = controller.get_summary()\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Summary:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total interventions: {summary['total_interventions']}\")\n",
        "print(f\"Max Î»(t): {summary['max_lambda']:.4f}\")\n",
        "print(f\"Mean Î»(t): {summary['mean_lambda']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Visualize the Results\n",
        "\n",
        "Let's plot the Î»(t) curve to see how the controller responded to instability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot Î»(t) curve with interventions\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot 1: Lambda curve\n",
        "plt.subplot(1, 2, 1)\n",
        "steps = range(len(lambda_values))\n",
        "plt.plot(steps, lambda_values, linewidth=2, label='Î»(t)', color='#2E86AB')\n",
        "plt.axhline(y=controller.threshold, color='#A23B72', linestyle='--', linewidth=2, label='Threshold')\n",
        "\n",
        "# Mark interventions\n",
        "rollback_steps = [i for i, a in enumerate(actions_taken) if a[\"action\"] == \"rollback\"]\n",
        "if rollback_steps:\n",
        "    plt.scatter(\n",
        "        rollback_steps,\n",
        "        [lambda_values[i] for i in rollback_steps],\n",
        "        color='#F18F01',\n",
        "        s=150,\n",
        "        marker='o',\n",
        "        label='Rollback',\n",
        "        zorder=5,\n",
        "        edgecolors='black',\n",
        "        linewidths=2\n",
        "    )\n",
        "\n",
        "plt.xlabel('Training Step', fontsize=12)\n",
        "plt.ylabel('Î»(t) - Stability Metric', fontsize=12)\n",
        "plt.title('CandorFlow Stability Monitoring (Simplified)', fontsize=13, fontweight='bold')\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Loss curve\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(steps, losses, linewidth=2, color='#C73E1D', label='Loss')\n",
        "\n",
        "if rollback_steps:\n",
        "    plt.scatter(\n",
        "        rollback_steps,\n",
        "        [losses[i] for i in rollback_steps],\n",
        "        color='#F18F01',\n",
        "        s=150,\n",
        "        marker='o',\n",
        "        label='Rollback',\n",
        "        zorder=5,\n",
        "        edgecolors='black',\n",
        "        linewidths=2\n",
        "    )\n",
        "\n",
        "plt.xlabel('Training Step', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training Loss', fontsize=13, fontweight='bold')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../plots/notebook_demo.png', dpi=150, bbox_inches='tight')\n",
        "print(\"âœ“ Saved plot to ../plots/notebook_demo.png\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸ“Š Observation:\")\n",
        "print(\"  â€¢ Î»(t) was low and stable during normal training\")\n",
        "print(\"  â€¢ Around step 25, we injected gradient noise\")\n",
        "print(\"  â€¢ Î»(t) spiked above threshold â†’ Controller intervened\")\n",
        "print(\"  â€¢ Training recovered after rollback + LR reduction\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Key Takeaways\n",
        "\n",
        "### What We Demonstrated âœ…\n",
        "\n",
        "1. **Early Warning**: Î»(t) detected instability *before* complete divergence\n",
        "2. **Automatic Intervention**: Controller rolled back without manual intervention\n",
        "3. **Recovery**: Training continued successfully after LR reduction\n",
        "4. **Simplicity**: Clean API with minimal code changes\n",
        "\n",
        "### What's Missing from Full System âŒ\n",
        "\n",
        "This demo showed a **basic proof-of-concept**. The full proprietary CandorFlow system includes:\n",
        "\n",
        "- **Universal Scaling Laws**: Î»(t) that works across all model architectures and domains\n",
        "- **Reflexive Ridge Algorithm**: Advanced mathematical framework for stability\n",
        "- **Predictive Modeling**: Forecast instabilities before they occur\n",
        "- **Multi-Signal Fusion**: Combine gradients, loss, activations, and more\n",
        "- **Cross-Domain Applications**: ECG monitoring, earthquake detection, market analysis\n",
        "- **Production Optimizations**: Minimal overhead, HPC integration, distributed training\n",
        "- **Advanced Control**: Adaptive thresholds, temporal smoothing, active inference\n",
        "\n",
        "### Next Steps ðŸš€\n",
        "\n",
        "To run more extensive demos:\n",
        "\n",
        "```bash\n",
        "# Full training demo with larger model\n",
        "python examples/demo_training_loop.py\n",
        "\n",
        "# Generate publication-quality plots\n",
        "python examples/demo_plots.py\n",
        "```\n",
        "\n",
        "### Learn More ðŸ“š\n",
        "\n",
        "- Read the full README: `../README.md`\n",
        "- Check the source code: `../candorflow/`\n",
        "- Contact us for information about the full proprietary system\n",
        "\n",
        "---\n",
        "\n",
        "**Thank you for trying CandorFlow!** ðŸŒŠ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Î»(t) curve with interventions\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot 1: Lambda curve\n",
        "plt.subplot(1, 2, 1)\n",
        "steps = range(len(lambda_values))\n",
        "plt.plot(steps, lambda_values, linewidth=2, label='Î»(t)', color='#2E86AB')\n",
        "plt.axhline(y=controller.threshold, color='#A23B72', linestyle='--', linewidth=2, label='Threshold')\n",
        "\n",
        "# Mark interventions\n",
        "rollback_steps = [i for i, a in enumerate(actions_taken) if a[\"action\"] == \"rollback\"]\n",
        "if rollback_steps:\n",
        "    plt.scatter(\n",
        "        rollback_steps,\n",
        "        [lambda_values[i] for i in rollback_steps],\n",
        "        color='#F18F01',\n",
        "        s=150,\n",
        "        marker='o',\n",
        "        label='Rollback',\n",
        "        zorder=5,\n",
        "        edgecolors='black',\n",
        "        linewidths=2\n",
        "    )\n",
        "\n",
        "plt.xlabel('Training Step', fontsize=12)\n",
        "plt.ylabel('Î»(t) - Stability Metric', fontsize=12)\n",
        "plt.title('CandorFlow Stability Monitoring (Simplified)', fontsize=13, fontweight='bold')\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Loss curve\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(steps, losses, linewidth=2, color='#C73E1D', label='Loss')\n",
        "\n",
        "if rollback_steps:\n",
        "    plt.scatter(\n",
        "        rollback_steps,\n",
        "        [losses[i] for i in rollback_steps],\n",
        "        color='#F18F01',\n",
        "        s=150,\n",
        "        marker='o',\n",
        "        label='Rollback',\n",
        "        zorder=5,\n",
        "        edgecolors='black',\n",
        "        linewidths=2\n",
        "    )\n",
        "\n",
        "plt.xlabel('Training Step', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training Loss', fontsize=13, fontweight='bold')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../plots/notebook_demo.png', dpi=150, bbox_inches='tight')\n",
        "print(\"âœ“ Saved plot to ../plots/notebook_demo.png\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸ“Š Observation:\")\n",
        "print(\"  â€¢ Î»(t) was low and stable during normal training\")\n",
        "print(\"  â€¢ Around step 25, we injected gradient noise\")\n",
        "print(\"  â€¢ Î»(t) spiked above threshold â†’ Controller intervened\")\n",
        "print(\"  â€¢ Training recovered after rollback + LR reduction\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ“ Disclaimer\n",
        "\n",
        "This notebook demonstrates **simplified, educational implementations** for illustration purposes only.\n",
        "\n",
        "**This is NOT the full proprietary CandorFlow system.**\n",
        "\n",
        "The complete system includes proprietary algorithms, universal scaling laws, reflexive computations, and cross-domain capabilities that are protected by pending patents and NOT included in this public demo.\n",
        "\n",
        "For inquiries about the full system, commercial licensing, or research collaborations, please contact the authors.\n",
        "\n",
        "**License**: This demo code is provided under the MIT License. See LICENSE file for details.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
